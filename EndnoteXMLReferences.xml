<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE references
  PUBLIC "-//XMLmind//DTD XLingPap//EN" "XLingPap.dtd">
<references><refAuthor name="** There was no author for this work! **" citename="** There was no author for this work! **" showAuthorName="yes"><refWork id="rTherewasnoauthorforthisworkIdent" showiso639-3codes="no"><refTitle>Identifying sounds in spectrograms</refTitle><webPage><url/></webPage></refWork></refAuthor><refAuthor name="** There was no author for this work! **" citename="** There was no author for this work! **" showAuthorName="yes"><refWork id="rTherewasnoauthorforthiswork2019Langu" showiso639-3codes="no"><refDate>2019</refDate><refTitle>Language Technology for Language Documentation and Revitalization</refTitle><webPage><url/></webPage></refWork></refAuthor><refAuthor name="** There was no author for this work! **" citename="** There was no author for this work! **" showAuthorName="yes"><refWork id="rTherewasnoauthorforthiswork2019PHOIB" showiso639-3codes="no"><refDate>2019</refDate><refTitle>PHOIBLE 2.0</refTitle><book><seriesEd plural="yes">Moran, Steven, McCloy, Daniel</seriesEd><series/><location>Jena</location><publisher>Max Planck Institute for the Science of Human History</publisher></book></refWork></refAuthor><refAuthor name="Abate, Solomon Teferra, Menzel, Wolfgang, Tafila, Bairu" citename="Abate, Solomon Teferra, Menzel, Wolfgang and Tafila, Bairu"><refWork id="rAbate2005AnAmh" showiso639-3codes="no"><refDate>2005</refDate><refTitle>An Amharic Speech Corpus for Large Vocabulary Continuous Speech Recognition</refTitle><proceedings><procTitle>INTERSPEECH-2005</procTitle></proceedings></refWork></refAuthor><refAuthor name="Amodei, Dario, Ananthanarayanan, Sundaram, Anubhai, Rishita, Bai, Jingliang, Battenberg, Eric, Case, Carl, Casper, Jared, Catanzaro, Bryan, Cheng, Qiang, Chen, Guoliang, others" citename="Amodei, Dario, Ananthanarayanan, Sundaram, Anubhai, Rishita, Bai, Jingliang, Battenberg, Eric, Case, Carl, Casper, Jared, Catanzaro, Bryan, Cheng, Qiang, Chen, Guoliang and others"><refWork id="rAmodei2016Deeps" showiso639-3codes="no"><refDate>2016</refDate><refTitle>Deep speech 2: End-to-end speech recognition in english and mandarin</refTitle><proceedings><procTitle>International conference on machine learning</procTitle><procPages>173-182</procPages></proceedings></refWork></refAuthor><refAuthor name="Baxter, Jonathan" citename="Baxter, Jonathan"><refWork id="rBaxter2000Amode" showiso639-3codes="no"><refDate>2000</refDate><refTitle>A model of inductive bias learning</refTitle><article><jTitle>Journal of artificial intelligence research</jTitle><jVol>12</jVol><jPages>149-198</jPages></article></refWork></refAuthor><refAuthor name="Ben-David, Shai, Schuller, Reba" citename="Ben-David, Shai and Schuller, Reba"><refWork id="rBenDavid2003Explo" showiso639-3codes="no"><refDate>2003</refDate><refTitle>Exploiting task relatedness for multiple task learning</refTitle><collection><collTitle>Learning Theory and Kernel Machines</collTitle><collPages>567-580</collPages><publisher>Springer</publisher></collection></refWork></refAuthor><refAuthor name="Bishop, Christopher M" citename="Bishop, Christopher M"><refWork id="rBishop2006Patte" showiso639-3codes="no"><refDate>2006</refDate><refTitle>Pattern recognition and machine learning</refTitle><book><publisher>springer</publisher></book></refWork></refAuthor><refAuthor name="Bojanowski, Piotr, Grave, Edouard, Joulin, Armand, Mikolov, Tomas" citename="Bojanowski, Piotr, Grave, Edouard, Joulin, Armand and Mikolov, Tomas"><refWork id="rBojanowski2017Enric" showiso639-3codes="no"><refDate>2017</refDate><refTitle>Enriching word vectors with subword information</refTitle><article><jTitle>Transactions of the Association for Computational Linguistics</jTitle><jVol>5</jVol><jPages>135-146</jPages><publisher>MIT Press</publisher></article></refWork></refAuthor><refAuthor name="Braun, Stefan, Neil, Daniel, Liu, Shih-Chii" citename="Braun, Stefan, Neil, Daniel and Liu, Shih-Chii"><refWork id="rBraun2017Acurr" showiso639-3codes="no"><refDate>2017</refDate><refTitle>A curriculum learning method for improved noise robustness in automatic speech recognition</refTitle><proceedings><procTitle>2017 25th European Signal Processing Conference (EUSIPCO)</procTitle><procPages>548-552</procPages></proceedings></refWork></refAuthor><refAuthor name="Burget, Lukáš, Schwarz, Petr, Agarwal, Mohit, Akyazi, Pinar, Feng, Kai, Ghoshal, Arnab, Glembek, Ondřej, Goel, Nagendra, Karafiát, Martin, Povey, Daniel, others" citename="Burget, Lukáš, Schwarz, Petr, Agarwal, Mohit, Akyazi, Pinar, Feng, Kai, Ghoshal, Arnab, Glembek, Ondřej, Goel, Nagendra, Karafiát, Martin, Povey, Daniel and others"><refWork id="rBurget2010Multi" showiso639-3codes="no"><refDate>2010</refDate><refTitle>Multilingual acoustic modeling for speech recognition based on subspace Gaussian mixture models</refTitle><proceedings><procTitle>Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on</procTitle><procPages>4334-4337</procPages></proceedings></refWork></refAuthor><refAuthor name="Chan, William, Jaitly, Navdeep, Le, Quoc V, Google Brain, Vinyals" citename="Chan, William, Jaitly, Navdeep, Le, Quoc V and Google Brain, Vinyals"><refWork id="rChanListe" showiso639-3codes="no"><refTitle>Listen, Attend and Spell</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Chang, Shuangyu, Shastri, Lokendra, Greenberg, Steven" citename="Chang, Shuangyu, Shastri, Lokendra and Greenberg, Steven"><refWork id="rChang2000Autom" showiso639-3codes="no"><refDate>2000</refDate><refTitle>Automatic phonetic transcription of spontaneous speech (American English)</refTitle><proceedings><procTitle>Sixth International Conference on Spoken Language Processing</procTitle></proceedings></refWork></refAuthor><refAuthor name="Chen, Dongpeng, Mak, Brian, Leung, Cheung-Chi, Sivadas, Sunil" citename="Chen, Dongpeng, Mak, Brian, Leung, Cheung-Chi and Sivadas, Sunil"><refWork id="rChen2014Joint" showiso639-3codes="no"><refDate>2014</refDate><refTitle>Joint acoustic modeling of triphones and trigraphemes by multi-task learning deep neural networks for low-resource speech recognition</refTitle><proceedings><procTitle>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</procTitle><procPages>5592-5596</procPages></proceedings></refWork></refAuthor><refAuthor name="Chen, Zhuo, Watanabe, Shinji, Erdogan, Hakan, Hershey, John R" citename="Chen, Zhuo, Watanabe, Shinji, Erdogan, Hakan and Hershey, John R"><refWork id="rChen2015Speec" showiso639-3codes="no"><refDate>2015</refDate><refTitle>Speech enhancement and recognition using multi-task learning of long short-term memory recurrent neural networks</refTitle><proceedings><procTitle>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</procTitle><procVol>2015-Janua</procVol><procPages>3274-3278</procPages></proceedings></refWork></refAuthor><refAuthor name="Cieri, Christopher, Miller, David, Walker, Kevin" citename="Cieri, Christopher, Miller, David and Walker, Kevin"><refWork id="rCieri2004TheFi" showiso639-3codes="no"><refDate>2004</refDate><refTitle>The Fisher Corpus: a Resource for the Next Generations of Speech-to-Text.</refTitle><proceedings><procTitle>LREC</procTitle><procVol>4</procVol><procPages>69-71</procPages></proceedings></refWork></refAuthor><refAuthor name="Clements, G N" citename="Clements, G N"><refWork id="rClements2009Doess" showiso639-3codes="no"><refDate>2009</refDate><refTitle>Does sonority have a phonetic basis? Comments on the chapter by Vaux</refTitle><article><jTitle>Contemporary Views on Architecture and Representations in Phonological Theory</jTitle><jVol/><jPages>165-175</jPages></article></refWork></refAuthor><refAuthor name="Clements, G. N." citename="Clements, G. N."><refWork id="rClements2010Thero" showiso639-3codes="no"><refDate>2010</refDate><refTitle>The role of the sonority cycle in core syllabification</refTitle><collection><collTitle>Papers in Laboratory Phonology</collTitle><collPages>283-333</collPages><publisher>Cambridge University Press</publisher><doi>10.1017/cbo9780511627736.017</doi></collection></refWork></refAuthor><refAuthor name="Cohen, Paul S, Dharanipragada, Satyanarayana, Gros, Jerneja Zganec, Monkowski, Michael Daniel, Neti, Chalapathy, Roukos, Salim, Ward, Todd" citename="Cohen, Paul S, Dharanipragada, Satyanarayana, Gros, Jerneja Zganec, Monkowski, Michael Daniel, Neti, Chalapathy, Roukos, Salim and Ward, Todd"><refWork id="rCohen1997Towar" showiso639-3codes="no"><refDate>1997</refDate><refTitle>Towards a universal speech recognizer for multiple languages</refTitle><proceedings><procTitle>1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings</procTitle><procPages>591-598</procPages></proceedings></refWork></refAuthor><refAuthor name="Cui, Jia, Kingsbury, Brian, Ramabhadran, Bhuvana, Sethy, Abhinav, Audhkhasi, Kartik, Cui, Xiaodong, Kislal, Ellen, Mangu, Lidia, Nussbaum-Thom, Markus, Picheny, Michael, others" citename="Cui, Jia, Kingsbury, Brian, Ramabhadran, Bhuvana, Sethy, Abhinav, Audhkhasi, Kartik, Cui, Xiaodong, Kislal, Ellen, Mangu, Lidia, Nussbaum-Thom, Markus, Picheny, Michael and others"><refWork id="rCui2015Multi" showiso639-3codes="no"><refDate>2015</refDate><refTitle>Multilingual representations for low resource speech recognition and keyword search</refTitle><proceedings><procTitle>2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)</procTitle><procPages>259-266</procPages></proceedings></refWork></refAuthor><refAuthor name="Dalmia, Siddharth, Li, Xinjian, Metze, Florian, Black, Alan W" citename="Dalmia, Siddharth, Li, Xinjian, Metze, Florian and Black, Alan W"><refWork id="rDalmia2018Domai" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Domain robust feature extraction for rapid low resource asr development</refTitle><proceedings><procTitle>2018 IEEE Spoken Language Technology Workshop (SLT)</procTitle><procPages>258-265</procPages></proceedings></refWork></refAuthor><refAuthor name="Dalmia, Siddharth, Sanabria, Ramon, Metze, Florian, Black, Alan W" citename="Dalmia, Siddharth, Sanabria, Ramon, Metze, Florian and Black, Alan W"><refWork id="rDalmia2018Seque" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Sequence-Based Multi-lingual Low Resource Speech Recognition</refTitle><proceedings><procTitle>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</procTitle><procPages>4909-4913</procPages></proceedings></refWork></refAuthor><refAuthor name="Daniel, Jurafsky, Martin, James H" citename="Daniel, Jurafsky and Martin, James H"><refWork id="rDanielSpeec" showiso639-3codes="no"><refTitle>Speech and Language Processing</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Demuynck, Kris, Laureys, Tom, Gillis, Steven" citename="Demuynck, Kris, Laureys, Tom and Gillis, Steven"><refWork id="rDemuynck2002Autom" showiso639-3codes="no"><refDate>2002</refDate><refTitle>Automatic generation of phonetic transcriptions for large speech corpora</refTitle><proceedings><procTitle>Seventh International Conference on Spoken Language Processing</procTitle></proceedings></refWork></refAuthor><refAuthor name="Devlin, Jacob, Chang, Ming-Wei, Lee, Kenton, Toutanova, Kristina" citename="Devlin, Jacob, Chang, Ming-Wei, Lee, Kenton and Toutanova, Kristina"><refWork id="rDevlin2018BertP" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Bert: Pre-training of deep bidirectional transformers for language understanding</refTitle><article><jTitle>arXiv preprint arXiv:1810.04805</jTitle><jVol/></article></refWork></refAuthor><refAuthor name="DiCanio, Christian, Nam, Hosung, Whalen, Douglas H, Timothy Bunnell, H, Amith, Jonathan D, Garc\'\ia, Rey Castillo" citename="DiCanio, Christian, Nam, Hosung, Whalen, Douglas H, Timothy Bunnell, H, Amith, Jonathan D and Garc\'\ia, Rey Castillo"><refWork id="rDiCanio2013Using" showiso639-3codes="no"><refDate>2013</refDate><refTitle>Using automatic alignment to analyze endangered language data: Testing the viability of untrained alignment</refTitle><article><jTitle>The Journal of the Acoustical Society of America</jTitle><jVol>134</jVol><jPages>2235-2246</jPages><publisher>ASA</publisher></article></refWork></refAuthor><refAuthor name="Gelas, Hadrien, Besacier, Laurent, Pellegrino, François" citename="Gelas, Hadrien, Besacier, Laurent and Pellegrino, François"><refWork id="rGelas2012Devel" showiso639-3codes="no"><refDate>2012</refDate><refTitle>Developments of Swahili resources for an automatic speech recognition system</refTitle><proceedings><procTitle>Spoken Language Technologies for Under-Resourced Languages</procTitle></proceedings></refWork></refAuthor><refAuthor name="Godfrey, John J, Holliman, Edward C, McDaniel, Jane" citename="Godfrey, John J, Holliman, Edward C and McDaniel, Jane"><refWork id="rGodfrey1992SWITC" showiso639-3codes="no"><refDate>1992</refDate><refTitle>SWITCHBOARD: Telephone speech corpus for research and development</refTitle><proceedings><procTitle>Acoustics, Speech, and Signal Processing, 1992. ICASSP-92., 1992 IEEE International Conference on</procTitle><procVol>1</procVol><procPages>517-520</procPages></proceedings></refWork></refAuthor><refAuthor name="Graves, Alex, Fernández, Santiago, Gomez, Faustino, Schmidhuber, Jürgen" citename="Graves, Alex, Fernández, Santiago, Gomez, Faustino and Schmidhuber, Jürgen"><refWork id="rGraves2006Conne" showiso639-3codes="no"><refDate>2006</refDate><refTitle>Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</refTitle><proceedings><procTitle>Proceedings of the 23rd international conference on Machine learning</procTitle><procPages>369-376</procPages></proceedings></refWork></refAuthor><refAuthor name="Graves, Alex, Jaitly, Navdeep" citename="Graves, Alex and Jaitly, Navdeep"><refWork id="rGraves2014Towar" showiso639-3codes="no"><refDate>2014</refDate><refTitle>Towards End-To-End Speech Recognition with Recurrent Neural Networks</refTitle><article><jTitle>JMLR Workshop and Conference Proceedings</jTitle><jVol>32</jVol><jPages>1764-1772</jPages><doi>10.1145/1143844.1143891</doi></article></refWork></refAuthor><refAuthor name="Gutkin, Alexander, Ha, Linne, Jansche, Martin, Pipatsrisawat, Knot, Sproat, Richard" citename="Gutkin, Alexander, Ha, Linne, Jansche, Martin, Pipatsrisawat, Knot and Sproat, Richard"><refWork id="rGutkinTTSfo" showiso639-3codes="no"><refTitle>TTS for Low Resource Languages: A Bangla Synthesizer.</refTitle><proceedings><procTitle/></proceedings></refWork></refAuthor><refAuthor name="Hannun, Awni Y, Maas, Andrew L, Jurafsky, Daniel, Ng, Andrew Y" citename="Hannun, Awni Y, Maas, Andrew L, Jurafsky, Daniel and Ng, Andrew Y"><refWork id="rHannun2014First" showiso639-3codes="no"><refDate>2014</refDate><refTitle>First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs</refTitle><article><jTitle>arXiv</jTitle><jVol/><jPages>1-7</jPages></article></refWork></refAuthor><refAuthor name="Heigold, Georg, Vanhoucke, Vincent, Senior, Alan, Nguyen, Patrick, Ranzato, Marc’Aurelio, Devin, Matthieu, Dean, Jeffrey" citename="Heigold, Georg, Vanhoucke, Vincent, Senior, Alan, Nguyen, Patrick, Ranzato, Marc’Aurelio, Devin, Matthieu and Dean, Jeffrey"><refWork id="rHeigold2013Multi" showiso639-3codes="no"><refDate>2013</refDate><refTitle>Multilingual acoustic models using distributed deep neural networks</refTitle><proceedings><procTitle>Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</procTitle><procPages>8619-8623</procPages></proceedings></refWork></refAuthor><refAuthor name="Huang, Jui-Ting, Li, Jinyu, Yu, Dong, Deng, Li, Gong, Yifan" citename="Huang, Jui-Ting, Li, Jinyu, Yu, Dong, Deng, Li and Gong, Yifan"><refWork id="rHuang2013Cross" showiso639-3codes="no"><refDate>2013</refDate><refTitle>Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers</refTitle><proceedings><procTitle>2013 IEEE International Conference on Acoustics, Speech and Signal Processing</procTitle><procPages>7304-7308</procPages></proceedings></refWork></refAuthor><refAuthor name="Hui Bu Jiayu Du, Xingyu Na Bengu Wu Hao Zheng" citename="Hui Bu Jiayu Du, Xingyu Na Bengu Wu Hao Zheng"><refWork id="rHuiBuJiayuDu2017AIShe" showiso639-3codes="no"><refDate>2017</refDate><refTitle>AIShell-1: An Open-Source Mandarin Speech Corpus and A Speech Recognition Baseline</refTitle><proceedings><procTitle>Oriental COCOSDA 2017</procTitle><procPages>Submitted</procPages></proceedings></refWork></refAuthor><refAuthor name="Johnson, Melvin, Schuster, Mike, Le, Quoc V, Krikun, Maxim, Wu, Yonghui, Chen, Zhifeng, Thorat, Nikhil, Viégas, Fernanda, Wattenberg, Martin, Corrado, Greg, others" citename="Johnson, Melvin, Schuster, Mike, Le, Quoc V, Krikun, Maxim, Wu, Yonghui, Chen, Zhifeng, Thorat, Nikhil, Viégas, Fernanda, Wattenberg, Martin, Corrado, Greg and others"><refWork id="rJohnson2017Googl" showiso639-3codes="no"><refDate>2017</refDate><refTitle>Google’s multilingual neural machine translation system: Enabling zero-shot translation</refTitle><article><jTitle>Transactions of the Association for Computational Linguistics</jTitle><jVol>5</jVol><jPages>339-351</jPages><publisher>MIT Press</publisher></article></refWork></refAuthor><refAuthor name="Kanda, Naoyuki, Takeda, Ryu, Obuchi, Yasunari" citename="Kanda, Naoyuki, Takeda, Ryu and Obuchi, Yasunari"><refWork id="rKanda2013Elast" showiso639-3codes="no"><refDate>2013</refDate><refTitle>Elastic spectral distortion for low resource speech recognition with deep neural networks</refTitle><proceedings><procTitle>Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on</procTitle><procPages>309-314</procPages></proceedings></refWork></refAuthor><refAuthor name="Kemelmacher-Shlizerman, Ira, Alpert, Sharon" citename="Kemelmacher-Shlizerman, Ira and Alpert, Sharon"><refWork id="rKemelmacherShlizermanCombi" showiso639-3codes="no"><refTitle>Combining Detection, Recognition and Segmentation</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Kim, Yoon, Jernite, Yacine, Sontag, David, Rush, Alexander M" citename="Kim, Yoon, Jernite, Yacine, Sontag, David and Rush, Alexander M"><refWork id="rKim2016Chara" showiso639-3codes="no"><refDate>2016</refDate><refTitle>Character-aware neural language models</refTitle><proceedings><procTitle>Thirtieth AAAI Conference on Artificial Intelligence</procTitle></proceedings></refWork></refAuthor><refAuthor name="Kingsbury, Brian" citename="Kingsbury, Brian"><refWork id="rKingsburyLATTI" showiso639-3codes="no"><refTitle>LATTICE-BASED OPTIMIZATION OF SEQUENCE CLASSIFICATION CRITERIA FOR NEURAL-NETWORK ACOUSTIC MODELING</refTitle><book/></refWork></refAuthor><refAuthor name="Kiros, Ryan, Zhu, Yukun, Salakhutdinov, Ruslan R, Zemel, Richard, Urtasun, Raquel, Torralba, Antonio, Fidler, Sanja" citename="Kiros, Ryan, Zhu, Yukun, Salakhutdinov, Ruslan R, Zemel, Richard, Urtasun, Raquel, Torralba, Antonio and Fidler, Sanja"><refWork id="rKiros2015Skipt" showiso639-3codes="no"><refDate>2015</refDate><refTitle>Skip-thought vectors</refTitle><proceedings><procTitle>Advances in neural information processing systems</procTitle><procPages>3294-3302</procPages></proceedings></refWork></refAuthor><refAuthor name="Kumar, Abhishek, Daume III, Hal" citename="Kumar, Abhishek and Daume III, Hal"><refWork id="rKumar2012Learn" showiso639-3codes="no"><refDate>2012</refDate><refTitle>Learning task grouping and overlap in multi-task learning</refTitle><article><jTitle>arXiv preprint arXiv:1206.6417</jTitle><jVol/></article></refWork></refAuthor><refAuthor name="Kumar, C Santhosh, Mohandas, V P, Li, Haizhou" citename="Kumar, C Santhosh, Mohandas, V P and Li, Haizhou"><refWork id="rKumar2005Multi" showiso639-3codes="no"><refDate>2005</refDate><refTitle>Multilingual speech recognition: A unified approach</refTitle><proceedings><procTitle>Ninth European Conference on Speech Communication and Technology</procTitle></proceedings></refWork></refAuthor><refAuthor name="Le, Quoc, Mikolov, Tomas" citename="Le, Quoc and Mikolov, Tomas"><refWork id="rLe2014Distr" showiso639-3codes="no"><refDate>2014</refDate><refTitle>Distributed representations of sentences and documents</refTitle><proceedings><procTitle>International conference on machine learning</procTitle><procPages>1188-1196</procPages></proceedings></refWork></refAuthor><refAuthor name="Lee, Matthew" citename="Lee, Matthew"><refWork id="rLee2019LTLDR" showiso639-3codes="no"><refDate>2019</refDate><refTitle>LTLDR19-speech/phoneInventory</refTitle><webPage><url/></webPage></refWork></refAuthor><refAuthor name="Lewis, M Paul" citename="Lewis, M Paul"><refWork id="rLewis2009Ethno" showiso639-3codes="no"><refDate>2009</refDate><refTitle>Ethnologue: Languages of the world</refTitle><book><publisher>SIL International</publisher></book></refWork></refAuthor><refAuthor name="Li, Bo, Sainath, Tara N, Sim, Khe Chai, Bacchiani, Michiel, Weinstein, Eugene, Nguyen, Patrick, Chen, Zhifeng, Wu, Yanghui, Rao, Kanishka" citename="Li, Bo, Sainath, Tara N, Sim, Khe Chai, Bacchiani, Michiel, Weinstein, Eugene, Nguyen, Patrick, Chen, Zhifeng, Wu, Yanghui and Rao, Kanishka"><refWork id="rLi2018Multi" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Multi-dialect speech recognition with a single sequence-to-sequence model</refTitle><proceedings><procTitle>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</procTitle><procPages>4749-4753</procPages></proceedings></refWork></refAuthor><refAuthor name="Li, Xinjian, Dalmia, Siddharth, Li, Juncheng, Lee, Matthew, Littel, Patrick, Yao, Jiali, Anastasopoulos, Antonios, Mortensen, David R, Neubig, Graham, Black, Alan W, Metz, Florian" citename="Li, Xinjian, Dalmia, Siddharth, Li, Juncheng, Lee, Matthew, Littel, Patrick, Yao, Jiali, Anastasopoulos, Antonios, Mortensen, David R, Neubig, Graham, Black, Alan W and Metz, Florian"><refWork id="rLi2020Unive" showiso639-3codes="no"><refDate>2020</refDate><refTitle>Universal Phone Recognition with a Multilingual Allophone System</refTitle><proceedings><procTitle/><procPages>5</procPages></proceedings></refWork></refAuthor><refAuthor name="Lin, Hui, Deng, Li, Yu, Dong, Gong, Yi-fan, Acero, Alex, Lee, Chin-Hui" citename="Lin, Hui, Deng, Li, Yu, Dong, Gong, Yi-fan, Acero, Alex and Lee, Chin-Hui"><refWork id="rLin2009Astud" showiso639-3codes="no"><refDate>2009</refDate><refTitle>A study on multilingual acoustic modeling for large vocabulary ASR</refTitle><proceedings><procTitle>2009 IEEE International Conference on Acoustics, Speech and Signal Processing</procTitle><procPages>4333-4336</procPages></proceedings></refWork></refAuthor><refAuthor name="Liu, Yi, Fung, Pascale, Yang, Yongsheng, Cieri, Christopher, Huang, Shudong, Graff, David" citename="Liu, Yi, Fung, Pascale, Yang, Yongsheng, Cieri, Christopher, Huang, Shudong and Graff, David"><refWork id="rLiu2006Hkust" showiso639-3codes="no"><refDate>2006</refDate><refTitle>Hkust/mts: A very large scale mandarin telephone speech corpus</refTitle><collection><collTitle>Chinese Spoken Language Processing</collTitle><collPages>724-735</collPages><publisher>Springer</publisher></collection></refWork></refAuthor><refAuthor name="Maas, Andrew L, Xie, Ziang, Jurafsky, Dan, Ng, Andrew Y" citename="Maas, Andrew L, Xie, Ziang, Jurafsky, Dan and Ng, Andrew Y"><refWork id="rMaasLexic" showiso639-3codes="no"><refTitle>Lexicon-Free Conversational Speech Recognition with Neural Networks</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Maaten, Laurens van der, Hinton, Geoffrey" citename="Maaten, Laurens van der and Hinton, Geoffrey"><refWork id="rMaaten2008Visua" showiso639-3codes="no"><refDate>2008</refDate><refTitle>Visualizing data using t-SNE</refTitle><article><jTitle>Journal of machine learning research</jTitle><jVol>9</jVol><jPages>2579-2605</jPages></article></refWork></refAuthor><refAuthor name="Maekawa, Kikuo" citename="Maekawa, Kikuo"><refWork id="rMaekawa2003Corpu" showiso639-3codes="no"><refDate>2003</refDate><refTitle>Corpus of Spontaneous Japanese: Its design and evaluation</refTitle><proceedings><procTitle>ISCA &amp; IEEE Workshop on Spontaneous Speech Processing and Recognition</procTitle></proceedings></refWork></refAuthor><refAuthor name="Matejka, Pavel, Schwarz, Petr, Cernock\`y, Jan, Chytil, Pavel" citename="Matejka, Pavel, Schwarz, Petr, Cernock\`y, Jan and Chytil, Pavel"><refWork id="rMatejka2005Phono" showiso639-3codes="no"><refDate>2005</refDate><refTitle>Phonotactic language identification using high quality phoneme recognition</refTitle><proceedings><procTitle>Ninth European Conference on Speech Communication and Technology</procTitle></proceedings></refWork></refAuthor><refAuthor name="Miao, Yajie, Gowayyed, Mohammad, Metze, Florian" citename="Miao, Yajie, Gowayyed, Mohammad and Metze, Florian"><refWork id="rMiao2015EESEN" showiso639-3codes="no"><refDate>2015</refDate><refTitle>EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding</refTitle><proceedings><procTitle>Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Workshop on</procTitle><procPages>167-174</procPages></proceedings></refWork></refAuthor><refAuthor name="Michaud, Alexis, Adams, Oliver, Cohn, Trevor Anthony, Neubig, Graham, Guillaume, Séverine" citename="Michaud, Alexis, Adams, Oliver, Cohn, Trevor Anthony, Neubig, Graham and Guillaume, Séverine"><refWork id="rMichaud2018Integ" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Integrating automatic transcription into the language documentation workflow: Experiments with Na data and the Persephone toolkit</refTitle><article><jTitle/><jVol/><publisher>University of Hawaii Press</publisher></article></refWork></refAuthor><refAuthor name="Mortensen, David R, Dalmia, Siddharth, Littell, Patrick" citename="Mortensen, David R, Dalmia, Siddharth and Littell, Patrick"><refWork id="rMortensen2018Epitr" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Epitran: Precision G2P for Many Languages.</refTitle><proceedings><procTitle>LREC</procTitle></proceedings></refWork></refAuthor><refAuthor name="Neubig, Graham, Littell, Patrick, Chen, Chian-Yu, Lee, Jean, Li, Zirui, Lin, Yu-Hsiang, Zhang, Yuyan" citename="Neubig, Graham, Littell, Patrick, Chen, Chian-Yu, Lee, Jean, Li, Zirui, Lin, Yu-Hsiang and Zhang, Yuyan"><refWork id="rNeubig2018Towar" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Towards a General-Purpose Linguistic Annotation Backend</refTitle><article><jTitle>arXiv preprint arXiv:1812.05272</jTitle><jVol/></article></refWork></refAuthor><refAuthor name="Panayotov, Vassil, Chen, Guoguo, Povey, Daniel, Khudanpur, Sanjeev" citename="Panayotov, Vassil, Chen, Guoguo, Povey, Daniel and Khudanpur, Sanjeev"><refWork id="rPanayotov2015Libri" showiso639-3codes="no"><refDate>2015</refDate><refTitle>Librispeech: an ASR corpus based on public domain audio books</refTitle><proceedings><procTitle>Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on</procTitle><procPages>5206-5210</procPages></proceedings></refWork></refAuthor><refAuthor name="Pavlovic, Caslav" citename="Pavlovic, Caslav"><refWork id="rPavlovic2018SII—S" showiso639-3codes="no"><refDate>2018</refDate><refTitle>SII—Speech intelligibility index standard: ANSI S3.5 1997</refTitle><article><jTitle>The Journal of the Acoustical Society of America</jTitle><jVol>143</jVol><jPages>1906-1906</jPages><publisher>Acoustical Society of America (ASA)</publisher><doi>10.1121/1.5036206</doi></article></refWork></refAuthor><refAuthor name="Povey, Daniel, Ghoshal, Arnab, Boulianne, Gilles, Burget, Lukas, Glembek, Ondrej, Goel, Nagendra, Hannemann, Mirko, Motlicek, Petr, Qian, Yanmin, Schwarz, Petr, others" citename="Povey, Daniel, Ghoshal, Arnab, Boulianne, Gilles, Burget, Lukas, Glembek, Ondrej, Goel, Nagendra, Hannemann, Mirko, Motlicek, Petr, Qian, Yanmin, Schwarz, Petr and others"><refWork id="rPovey2011TheKa" showiso639-3codes="no"><refDate>2011</refDate><refTitle>The Kaldi speech recognition toolkit</refTitle><proceedings><procTitle>IEEE 2011 workshop on automatic speech recognition and understanding</procTitle></proceedings></refWork></refAuthor><refAuthor name="Povey, Daniel, Peddinti, Vijayaditya, Galvez, Daniel, Ghahrmani, Pegah, Manohar, Vimal, Na, Xingyu, Wang, Yiming, Khudanpur, Sanjeev" citename="Povey, Daniel, Peddinti, Vijayaditya, Galvez, Daniel, Ghahrmani, Pegah, Manohar, Vimal, Na, Xingyu, Wang, Yiming and Khudanpur, Sanjeev"><refWork id="rPoveyPurel" showiso639-3codes="no"><refTitle>Purely sequence-trained neural networks for ASR based on lattice-free MMI</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Rhebergen, K S ;, Versfeld, N J" citename="Rhebergen, K S ; and Versfeld, N J"><refWork id="rRhebergen2005UvADA" showiso639-3codes="no"><refDate>2005</refDate><refTitle>UvA-DARE (Digital Academic Repository) A Speech Intelligibility Index-based approach to predict the speech reception threshold for sentences in fluctuating noise for normal-hearing listeners</refTitle><article><jTitle/><jVol/><doi>10.1121/1.1861713</doi></article></refWork></refAuthor><refAuthor name="Riccardi, Giuseppe, Hakkani-Tur, Dilek" citename="Riccardi, Giuseppe and Hakkani-Tur, Dilek"><refWork id="rRiccardi2005Activ" showiso639-3codes="no"><refDate>2005</refDate><refTitle>Active learning: Theory and applications to automatic speech recognition</refTitle><article><jTitle>IEEE transactions on speech and audio processing</jTitle><jVol>13</jVol><jPages>504-511</jPages><publisher>IEEE</publisher></article></refWork></refAuthor><refAuthor name="Rousseau, Anthony, Deléglise, Paul, Esteve, Yannick" citename="Rousseau, Anthony, Deléglise, Paul and Esteve, Yannick"><refWork id="rRousseau2012TEDLI" showiso639-3codes="no"><refDate>2012</refDate><refTitle>TED-LIUM: an Automatic Speech Recognition dedicated corpus.</refTitle><proceedings><procTitle>LREC</procTitle><procPages>125-129</procPages></proceedings></refWork></refAuthor><refAuthor name="Saraclar, Murat" citename="Saraclar, Murat"><refWork id="rSaraclar2012Turki" showiso639-3codes="no"><refDate>2012</refDate><refTitle>Turkish broadcast news speech and transcripts LDC2012S06</refTitle><article><jTitle>Philadelphia, Linguistic Data Consortium, Web Download</jTitle><jVol/></article></refWork></refAuthor><refAuthor name="Schultz, Tanja" citename="Schultz, Tanja"><refWork id="rSchultz2002Globa" showiso639-3codes="no"><refDate>2002</refDate><refTitle>GlobalPhone: a multilingual speech and text database developed at Karlsruhe University</refTitle><proceedings><procTitle>Seventh International Conference on Spoken Language Processing</procTitle></proceedings></refWork></refAuthor><refAuthor name="Schultz, Tanja, Waibel, Alex" citename="Schultz, Tanja and Waibel, Alex"><refWork id="rSchultz1997Fastb" showiso639-3codes="no"><refDate>1997</refDate><refTitle>Fast bootstrapping of LVCSR systems with multilingual phoneme sets</refTitle><proceedings><procTitle>Fifth European Conference on Speech Communication and Technology</procTitle></proceedings></refWork><refWork id="rSchultz1998Langu" showiso639-3codes="no"><refDate>1998</refDate><refTitle>Language independent and language adaptive large vocabulary speech recognition</refTitle><proceedings><procTitle>Fifth International Conference on Spoken Language Processing</procTitle></proceedings></refWork><refWork id="rSchultz2001Langu" showiso639-3codes="no"><refDate>2001</refDate><refTitle>Language-independent and language-adaptive acoustic modeling for speech recognition</refTitle><article><jTitle>Speech Communication</jTitle><jVol>35</jVol><jPages>31-51</jPages><publisher>Elsevier</publisher></article></refWork></refAuthor><refAuthor name="Silberer, Amanda Beth, Bentler, Ruth, Wu, Yu Hsiang" citename="Silberer, Amanda Beth, Bentler, Ruth and Wu, Yu Hsiang"><refWork id="rSilberer2015Theim" showiso639-3codes="no"><refDate>2015</refDate><refTitle>The importance of high-frequency audibility with and without visual cues on speech recognition for listeners with normal hearing</refTitle><article><jTitle>International Journal of Audiology</jTitle><jVol>54</jVol><jPages>865-872</jPages><doi>10.3109/14992027.2015.1051666</doi></article></refWork></refAuthor><refAuthor name="Soltau, Hagen, Liao, Hank, Sak, Hasim" citename="Soltau, Hagen, Liao, Hank and Sak, Hasim"><refWork id="rSoltau2016WordC" showiso639-3codes="no"><refDate>2016</refDate><refTitle>Word CTC</refTitle><article><jTitle/><jVol/><doi>10.21437/Interspeech.2017-1566</doi></article></refWork></refAuthor><refAuthor name="Sriram, Anuroop, Jun, Heewoo, Satheesh, Sanjeev, Coates, Adam" citename="Sriram, Anuroop, Jun, Heewoo, Satheesh, Sanjeev and Coates, Adam"><refWork id="rSriramColdF" showiso639-3codes="no"><refTitle>Cold Fusion: Training Seq2Seq Models Together with Language Models</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Stolcke, Andreas, Grezl, Frantisek, Hwang, Mei-Yuh, Lei, Xin, Morgan, Nelson, Vergyri, Dimitra" citename="Stolcke, Andreas, Grezl, Frantisek, Hwang, Mei-Yuh, Lei, Xin, Morgan, Nelson and Vergyri, Dimitra"><refWork id="rStolcke2006Cross" showiso639-3codes="no"><refDate>2006</refDate><refTitle>Cross-domain and cross-language portability of acoustic features estimated by multilayer perceptrons</refTitle><proceedings><procTitle>Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on</procTitle><procVol>1</procVol><procPages>I-I</procPages></proceedings></refWork></refAuthor><refAuthor name="STQ" citename="STQ"><refWork id="rSTQ2018TR103" showiso639-3codes="no"><refDate>2018</refDate><refTitle>TR 103 225 - V1.1.1 - Speech and multimedia Transmission Quality (STQ); Transmission quality and speech intelligibility for hearing impaired people</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Stüker, Sebastian, Metze, Florian, Schultz, Tanja, Waibel, Alex" citename="Stüker, Sebastian, Metze, Florian, Schultz, Tanja and Waibel, Alex"><refWork id="rStüker2003Integ" showiso639-3codes="no"><refDate>2003</refDate><refTitle>Integrating multilingual articulatory features into speech recognition</refTitle><proceedings><procTitle>Eighth European Conference on Speech Communication and Technology</procTitle></proceedings></refWork></refAuthor><refAuthor name="Swietojanski, Pawel, Ghoshal, Arnab, Renals, Steve" citename="Swietojanski, Pawel, Ghoshal, Arnab and Renals, Steve"><refWork id="rSwietojanski2012Unsup" showiso639-3codes="no"><refDate>2012</refDate><refTitle>Unsupervised cross-lingual knowledge transfer in DNN-based LVCSR</refTitle><proceedings><procTitle>Spoken Language Technology Workshop (SLT), 2012 IEEE</procTitle><procPages>246-251</procPages></proceedings></refWork></refAuthor><refAuthor name="Tachbelie, Martha Yifiru, Abate, Solomon Teferra, Besacier, Laurent" citename="Tachbelie, Martha Yifiru, Abate, Solomon Teferra and Besacier, Laurent"><refWork id="rTachbelie2014Using" showiso639-3codes="no"><refDate>2014</refDate><refTitle>Using different acoustic, lexical and language modeling units for ASR of an under-resourced language–Amharic</refTitle><article><jTitle>Speech Communication</jTitle><jVol>56</jVol><jPages>181-194</jPages><publisher>Elsevier</publisher></article></refWork></refAuthor><refAuthor name="Tong, Sibo, Garner, Philip N, Bourlard, Hervé" citename="Tong, Sibo, Garner, Philip N and Bourlard, Hervé"><refWork id="rTong2017Aninv" showiso639-3codes="no"><refDate>2017</refDate><refTitle>An investigation of deep neural networks for multilingual speech recognition training and adaptation</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Toshniwal, Shubham, Sainath, Tara N, Weiss, Ron J, Li, Bo, Moreno, Pedro, Weinstein, Eugene, Rao, Kanishka" citename="Toshniwal, Shubham, Sainath, Tara N, Weiss, Ron J, Li, Bo, Moreno, Pedro, Weinstein, Eugene and Rao, Kanishka"><refWork id="rToshniwal2018Multi" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Multilingual speech recognition with a single end-to-end model</refTitle><proceedings><procTitle>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</procTitle><procPages>4904-4908</procPages></proceedings></refWork></refAuthor><refAuthor name="Tüske, Zoltán, Pinto, Joel, Willett, Daniel, Schlüter, Ralf" citename="Tüske, Zoltán, Pinto, Joel, Willett, Daniel and Schlüter, Ralf"><refWork id="rTüske2013Inves" showiso639-3codes="no"><refDate>2013</refDate><refTitle>Investigation on cross-and multilingual MLP features under matched and mismatched acoustical conditions</refTitle><proceedings><procTitle>Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</procTitle><procPages>7349-7353</procPages></proceedings></refWork></refAuthor><refAuthor name="Vertanen, Keith" citename="Vertanen, Keith"><refWork id="rVertanenAnOve" showiso639-3codes="no"><refTitle>An Overview of Discriminative Training for Speech Recognition</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Vesel\`y, Karel, Karafiát, Martin, Grézl, František, Janda, Miloš, Egorova, Ekaterina" citename="Vesel\`y, Karel, Karafiát, Martin, Grézl, František, Janda, Miloš and Egorova, Ekaterina"><refWork id="rVesel\y2012Thela" showiso639-3codes="no"><refDate>2012</refDate><refTitle>The language-independent bottleneck features</refTitle><proceedings><procTitle>Spoken Language Technology Workshop (SLT), 2012 IEEE</procTitle><procPages>336-341</procPages></proceedings></refWork></refAuthor><refAuthor name="Vu, Ngoc Thang, Metze, Florian, Schultz, Tanja" citename="Vu, Ngoc Thang, Metze, Florian and Schultz, Tanja"><refWork id="rVu2012Multi" showiso639-3codes="no"><refDate>2012</refDate><refTitle>Multilingual bottle-neck features and its application for under-resourced languages</refTitle><proceedings><procTitle>Proc. 3rd Workshop on Spoken Language Technologies for Under-resourced Languages</procTitle><location>Cape Town; S. Africa</location></proceedings></refWork></refAuthor><refAuthor name="Vu, Ngoc Thang, Schultz, Tanja" citename="Vu, Ngoc Thang and Schultz, Tanja"><refWork id="rVu2013Multi" showiso639-3codes="no"><refDate>2013</refDate><refTitle>Multilingual multilayer perceptron for rapid language adaptation between and across language families.</refTitle><proceedings><procTitle>Interspeech</procTitle><procPages>515-519</procPages></proceedings></refWork></refAuthor><refAuthor name="Warnes, Gregory R, Warnes Consulting, Gregory R" citename="Warnes, Gregory R and Warnes Consulting, Gregory R"><refWork id="rWarnes2018Calcu" showiso639-3codes="no"><refDate>2018</refDate><refTitle>Calculating Speech Intelligibility Index (SII) using R</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor><refAuthor name="Watanabe, Shinji, Hori, Takaaki, Hershey, John R" citename="Watanabe, Shinji, Hori, Takaaki and Hershey, John R"><refWork id="rWatanabe2017Langu" showiso639-3codes="no"><refDate>2017</refDate><refTitle>Language independent end-to-end architecture for joint language identification and speech recognition</refTitle><proceedings><procTitle>2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</procTitle><procPages>265-271</procPages></proceedings></refWork></refAuthor><refAuthor name="Xiong, Wayne, Droppo, Jasha, Huang, Xuedong, Seide, Frank, Seltzer, Mike, Stolcke, Andreas, Yu, Dong, Zweig, Geoffrey" citename="Xiong, Wayne, Droppo, Jasha, Huang, Xuedong, Seide, Frank, Seltzer, Mike, Stolcke, Andreas, Yu, Dong and Zweig, Geoffrey"><refWork id="rXiong2016Achie" showiso639-3codes="no"><refDate>2016</refDate><refTitle>Achieving human parity in conversational speech recognition</refTitle><article><jTitle>arXiv preprint arXiv:1610.05256</jTitle><jVol/></article></refWork></refAuthor><refAuthor name="Zenkel, Thomas, Sanabria, Ramon, Metze, Florian, Niehues, Jan, Sperber, Matthias, Stüker, Sebastian, Waibel, Alex" citename="Zenkel, Thomas, Sanabria, Ramon, Metze, Florian, Niehues, Jan, Sperber, Matthias, Stüker, Sebastian and Waibel, Alex"><refWork id="rZenkel2017Compa" showiso639-3codes="no"><refDate>2017</refDate><refTitle>Comparison of Decoding Strategies for CTC Acoustic Models</refTitle><article><jTitle/><jVol/></article></refWork></refAuthor></references>